#+TITLE: Introduction
#+AUTHOR: Jonathan Reeve

* Introduction
The early 20th century saw a dramatic change in British literature. The end of the Victorian era, with the death of Queen Victoria in 1901, symbolized for many the beginning of a new literary period, and with it came a new aesthetics. This new aesthetics distinguishes itself from all those previous by means of its approach to visuality: not only did the writers of this generation /write/ differently, but they began to /see/ differently, as well. This dissertation investigates the changes in visuality that so strongly characterize this tumultuous time in literary history, using a blend of qualitative and quantitative methods. Modeling imagination using techniques from computer science, statistics, and computational linguistics, I reveal the depth of the explosion of color and shape at the turn of the century, and present the circumstances, and the causal agents, of this phenomenon.

Consider, as a starting point, this passage from Jane Austen's /Pride and Prejudice/, from 1813:

#+begin_quote
At length the Parsonage was discernible. The garden sloping to the road, the house standing in it, the green pales and the laurel hedge, every thing declared they were arriving. Mr. Collins and Charlotte appeared at the door, and the carriage stopped at the small gate, which led by a short gravel walk to the house, amidst the nods and smiles of the whole party. In a moment they were all out of the chaise, rejoicing at the sight of each other. Mrs. Collins welcomed her friend with the liveliest pleasure, and Elizabeth was more and more satisfied with coming, when she found herself so affectionately received. She saw instantly that her cousin's manners were not altered by his marriage; his formal civility was just what it had been, and he detained her some minutes at the gate to hear and satisfy his enquiries after all her family. They were then, with no other delay than his pointing out the neatness of the entrance, taken into the house; and as soon as they were in the parlour, he welcomed them a second time with ostentatious formality to his humble abode, and punctually repeated all his wife's offers of refreshment.
#+end_quote

This passage contains concrete descriptors of people, places and things, and paints a clear and memorable tableau of the parsonage. Through the eyes of Austen's narrator, we see a house with a garden, a hedge, a gravel walk, and a small gate; an interior parlor, where drinks are being served, and where people are nodding and smiling. Yet despite all of this, this description is heavily subordinated to the interpersonal cordialities, relations, and emotions. We see indeed that the pales are "green," and the hedge made of laurel, but these things exist only to "declare they were arriving." In the foreground, we see a meeting between Elizabeth and Mr. and Mrs Collins, which is described in abstract emotional terms, emphasizing "the liveliest pleasure," in which Elizabeth is "more and more satisfied," and feels "affectionately received." We hear of vague "manners," "civility," and "enquiries after all her family," a certain "neatness" of the house, and the "ostentatious formality" of his welcome. While we should not dismiss these abstractions as /mere/ social drama---Austen's famously knowing style frequently contains layers of subtexts of satire or social commentary---they nonetheless exemplify a mode which is more concerned with social experience than vision. Despite the modicum of description in this passage, we will later discover, though computational analysis, that Austen is among the least visual writers of the 19th and 20th centuries.

Now, in contrast, consider a passage from our destination, this passage from Virginia Woolf's /To the Lighthouse/, from over a hundred years later, in 1927:

#+begin_quote
The jacmanna was bright violet; the wall staring white. She would not have considered it honest to tamper with the bright violet and the staring white, since she saw them like that, fashionable though it was, since Mr. Paunceforte's visit, to see everything pale, elegant, semitransparent. Then beneath the colour there was the shape. She could see it all so clearly, so commandingly, when she looked: it was when she took her brush in hand that the whole thing changed. It was in that moment's flight between the picture and her canvas that the demons set on her who often brought her to the verge of tears and made this passage from conception to work as dreadful as any down a dark passage for a child. Such she often felt herself—struggling against terrific odds to maintain her courage; to say: "But this is what I see; this is what I see," and so to clasp some miserable remnant of her vision to her breast, which a thousand forces did their best to pluck from her.
#+end_quote

In contrast, Woolf's descriptive passage is thickly indulgent in its visuality. Lily Briscoe, painting a clematis, sees it through the eyes of a painter, and the word "see," in various forms, appears five times. There is a specificity of color which we rarely see in earlier literature: not just /violet/ or /white/, but /bright violet/ and /staring white/. Furthermore, the experience of this color has a stark, post-impressionist quality: it is not /pale, elegant, semitransparent,/ but /staring./ In addition to the color, perceived by the eye's retinal cones, there is the shape, perceived by its rods. This passage is not only visual, but ocular: it deals with perception as it operates before its distillation into feeling. Although there are emotions present here, too, as in Austen, with "demons" bringing her "to the verge of tears," Lily's primary concern is her vision, as she repeats: "this is what I see; this is what I see."

So how do we get from point A to point B, from Austen to Woolf? This is a difficult question, since chronology alone cannot account for all these differences. For one, there is a huge generic gap: Austen writes within the genre of the social drama, romance, or social satire, depending on your point of view. Woolf's novel, however, is a /Künstlerroman/ of sorts, and belongs to a high modernist genre of art-novel. There are also authorial styles to consider, as well as the writers' biographies that conditioned them: Austen's social sphere and Woolf's Bloomsbury, with its art critics. Character voices are also important variables: the differences between Austen's narrator, aware of Elizabeth, and the free indirect discourse informed by Lily's thoughts. This is where computational analysis helps. By analyzing thousands of novels and poems, computationally---many more than a single human could hope to read---we can begin to isolate chronological signals, and adjust for the influence of genre, style, voice, and other factors. I argue that a large part of this diachronic development is visual.

The title of this dissertation, "The Eye of Modernism," alludes to the changes in ocularities at the turn of the century: a turn towards the visual, and to the workings of the eye. First, I should explain that I mean "eye" in a more literal sense than it is usually used, using the retina as my guiding metaphor. The eye's retina is composed of two primary receptor types: cones, primarily responsible for color vision, and rods, primarily responsible for perception of shapes and objects. These I map onto my first two chapters.

In Chapter 1, the longest chapter, I discuss color, the phenomenon perceived by retinal cones. I develop a computational model of literary imagination, capable of inferring color values from color expressions, adjectives and nouns with inherent color properties, and other visual passages in text. Using this model, I study the changes in literary color over time, and find, among other trends, that there was a significant increase over the turn of the century, most notably around 1910. Pulling from a broad theoretical base, I explain this phenomenon, and complicate it, using the period's writings in philosophy, anthropology, and literary history, among other disciplines.

In Chapter 2, I discuss shape and object vision, phenomena perceived by retinal rods. The quantitative analysis I employ here uses neural networks to effect word sense disambiguation on a large corpus, deriving WordNet senses across a large corpus of novels and poems. Here, too, I find that objects and other shapes become more common over this time period, although to less of an extent as with color. I explain this trend in conversation with thing theory and body theory, as bodies and body parts are a subset of things, in the lexical hierarchy I use.

Finally, in Chapter 3, I synthesize these two facets of perception into the image, and trace the development of the textual image.  Here, I train a neural network to recognize literary description, and find that, to my surprise, descriptive paragraphs largely decline in popularity over time. This makes it more difficult to explain the rise in visuality in this period, and so I turn to other contemporaneous movements, such as imagism and literary impressionism.

Unlike the eye, the modernism of this dissertation's title is much harder to delineate. I didn't initially intend to study only modernist works, which would severely limit the scope of this study. Rather, most of the novels and collections of poems that appear at the tops of these lists are ones we tend to recognize as modernist, or as high modernist: James Joyce's /Ulysses/ and /A Portrait of the Artist as a Young Man/, Virginia Woolf's /Jacob's Room/ and other novels, Katherine Mansfield's short stories, and works by E.M. Forster, Ford Madox Ford, and other familiar figures. This makes it seem that the visuality I'm detecting here is not merely one of the moment, that is, of /modernity,/ but of a /modernism/.

The /-ism/ suffix implies a kind of deliberate organization, or unifying ideology: a movement which aims towards a new kind of writing. By closely examining the theoretical writings of this period, I will show not only /what/ happens, that is, the explosion of visuality around the turn of the century, but /why/ and /how/ it happens.

* Background

In the famous preface to his 1897 novella /The Nigger of the Narcissus/, Joseph Conrad announces that his project is, "by the power of the written word," "to make you hear, to make you feel, ... before all, to make you /see/. That---and no more, and it is everything." I will argue that he means "seeing" more literally than we usually suppose: not merely in the metaphorical sense of seeing as understanding, but in the physiological sense, of seeing as a neuro-ocular process. Conrad explains that his task is to hold up, "before all eyes," a "passing phase of life ... to show its vibration, its colour, its form, and through its movement, its form, and its colour, reveal the substance of its truth" [cite:@conradPortableConrad2007 49]. This trinity---color, form, and vibration/movement---is so important to Conrad, or so conceptually slippery, that he allows it two iterations, even in an essay that stresses the importance of verbal economy. It is tempting to read these three words figuratively, to say that "colour," when describing "a passing phase of life" refers to an affective experience, rather than a hue, and that "form" refers to a conceptual structure, rather than the visual boundaries of physical objects. That would not be entirely wrong.
In fact, these, and more esoteric readings, are among the most typical.[fn::See, for example [cite/t:@ennsVibrationSoundBirth2013, 71]. Ludwig Schnauder calls this sequence a blend of "the terms and concepts of Impressionism with a Victorian insistence on the truthfulness and moral sincerity of fiction" [cite:@schnauderFreeWillDeterminism2009, 98].]
But they overlook an equally valuable surface reading: that color and form are physiologically distinguishable ocular categories, corresponding to the rods and cones of retinal photoreceptors, and that they depend on light (vibrations in the visible electromagnetic spectrum) and a temporal dimension along which their movements may be perceived.

We hear this sentiment echoed throughout this period. For example, here is Ford Madox Ford, writing in 1939:

#+begin_quote
The main and perhaps most passionate tenet of impressionism was the suppression of the author from the pages of his book. He must not comment; he must not narrate; he must present his impressions of his imaginary affairs as if he had been present at them [...] the author is invisible and almost unnoticeable and [...] his attempt has been, above all, to make you see. [cite:@ford1939march 840].
#+end_quote

The eye is more than just an adequate metaphor for the imagination of this period's writers. To understand modernism, one must first understand the image, along with its primary interface, and first image-processing neural apparatus, the eye. The analyses in this dissertation presuppose a chain of perceptual processes that translate, with loss between each step, between object, image, and text.

An object or scene is perceived, or imagined, at which point it enters the brain of the writer. From there, it is translated, however clumsily, into words. Those words are then read by the reader, who imagines them differently, creating a mental picture at some remove from the thing originally imagined. There are two imaginations at work, and two objects.

#+begin_html
<div class="mermaid">
graph TD
  Object_A -->|vision| Eye
  Eye --> Brain
  Brain -->|writing| Words
  Words -->|reading| Eye
  Eye --> Brain
  Brain -->|imagination| Object_B
</div>
#+end_html

On the one hand, this view of modernism is nothing new: the literary phenomena I'll be analyzing here involve imagery, description, and literary impression---all elements of fiction and poetry writing which have gone out of fashion as objects of study since the latter half of the 20th century.[fn::I chart exactly how these textual features have been ignored, in Chapter 3. See also [cite/t:@ryf1959;@su11_imagin;@goslee2011shelley;@alldritt1971visual].]
On the other hand, cognitive literary criticism, a brand of literary analysis which approaches literary study informed with recent findings in psychology and other cognitive sciences, is very much a new field, with a large number of annual publications.[fn::See [cite/t:@zunshine2015oxford].]

One of the more vivid theories of image in literature, to choose one example from the earlier period, is found in the work of I.A. Richards, a literary critic of the early twentieth century who was influential to the school of New Critics. In his /Principles of Literary Criticism/ he diagrams the process of seeing, reading, and understanding a literary image, using a distinctly optical framework, as shown in [cite:@fig:richards] [cite:@richards2003principles 106].

#+CAPTION: Richards's Optical Process of Reading
#+LABEL: fig:richards
[[file:images/richards.png]]

Richards explains that the six distinct processes depicted vertically here correspond to events happening in succession, through which these lines cross, as "streams of impulses flowing through in the mind" (113):

#+BEGIN_QUOTE
#+BEGIN_VERSE
I. The visual sensations of the printed words.
II. Images very closely associated with these sensations.
III. Images relatively free.
IV. References to, or 'thinkings of', various things.
V. Emotions.
VI. Affective-volitional attitudes. (106-7)
#+END_VERSE
#+END_QUOTE

Richards's schematic gives a sense of the complexity of the cognitive and emotional processes involved with reading words that bear visual significance. Not everyone produces mental images, but images that readers produce are amalgamations of memories, emotions, attitudes, and sensations. Crucially, they are optic. Consider the resemblance of Richards's diagram to an illustration of retinal nerves, shown in Figure 2.

#+CAPTION: Source: Rogers, /Perception/ [cite:@rogersPerceptionVeryShort2017]
#+LABEL: fig:optic-nerve
[[file:images/optic-nerve.png]]

Richards, along with the modernists and imagists he studied, understood the reading process as a fundamentally visual one, shaped and even controlled by the mechanisms of the eye. 

# Contemporary criticism has often pointed out these pairs, but almost always uses them as a starting place for symptomatic readings: for instance, in Peter Nicholls on the implications of "hard" modernism; Rachel duPlessis on gendered aspects of the "dry" and "wet" in Pound; and Gibson on the "dry" and "hard" as neoclassicist [cite:@nichollsHardSoftModernism2013; @duplessisPropoundingModernistMaleness2002; @gibsonCONTRADICTORYIMAGESCONFLICTING2011a]. Jesse Schotter admirably problematizes the material membranes of the image and writing with his notion of "hieroglyphic" modernism, which synthesizes materialities of writing and image-making [cite:@schotter2018hieroglyphic]. His notion of the hieroglyphic is one that fuses writing and image-production, and is present in the many faux-Egyptologies of the early 20th century, as well as in Pound's /chinoiseries/. For Martin Jay, the modernist moment is a "crisis in ocularcentrism" which reflects "a deep-seated distrust of the privileging of sight" [cite:@jay88_rise 309]. Claudia Olk, as well, argues that a break with realism in early 20th century writing shifts conceptions of the visual from a representational and "natural" visual epistemology, to one a more "conceptual" and less "positivist" one:

#+BEGIN_QUOTE
"The category of vision is not only central to many modernist texts, but also plays a key role in the unfolding paradigm of modernism itself. The received sense of a modernist break with realism, its pervasive interest in the workings of the individual mind, and its generic reclassifications of the novel also intimately affected the role of vision, which gained a conceptual rather than natural status. Whereas realist texts adhere to a visual language of representation and become legible within a positivist epistemology, modernist texts clearly depart from this positivist faith." [cite:@olkVaguenessVisionVeil2007 153]
#+END_QUOTE

Epistemologies of visual perception, then, are a subset of a larger discussion surrounding subjectivity in fiction of this period, and in particular, literary-historical shifts in the treatment of subjectivities. In /The Pound Era/, Hugh Kenner notes that despite Pound's official stance on Imagism, the movement is nonetheless "named for a component of the poem, not a state of the poet, and that its three principles establish technical, not psychic, criteria" [cite:@kennerPoundEra1971 179]. Literary images are subjective, created in the mind of the reader, according to instructions from the poet, yet those instructions must pretend to be at least partially objective, or they will not be effectively communicated. I hope to unravel here some of these contradictions, problematize some of these dichotomies, and extend the readings of these critics to include concrete visual properties of the images created and manipulated by the writers of this period.

# Some more review of contemporary criticism here

* Method
The methods I employ in this study blend quantitative and qualitative criticism. While qualitative literary analysis is nothing new to literary studies, quantitative criticism is relatively rare, and goes under a variety of names. I largely employ methods from computational literary analysis, a field at the intersection of data science, computational linguistics, and the sub-discipline of computer science known as natural language processing. This is a practice of a discipline, or disciplines, variously termed digital literary studies, cultural analytics, or computational literary studies, and which falls under a greater umbrella of digital humanities.[fn::For /digital literary studies/, see [cite/t:@siemens_companion_2013; and @hoover_digital_2014]. For /cultural analytics/, see [[https://culturalanalytics.org/][The Journal of Cultural Analytics]]. For /computational literary studies,/ see [[https://jcls.io/][The Journal of Computational Literary Studies]].]
There are dozens, if not hundreds, of articles, conference presentations, and the like, which deal with defining one or more of these new disciplines and practices---so much that one cannot help but wonder whether more energy is being expended in quibbling about nomenclature, than in doing the analytic work itself. For that reason, I prefer describing the work, rather than wasting time with situating it within a disciplinary framework that would have it called /digital humanities/, /digital literary studies,/ or otherwise, and just as often dismissed as such, by grumpy traditionalists. But a few words should be said about these terms.

In most cases, I prefer /computational/ to /digital/, for the work I'll be doing in the following chapters, since it's more action-oriented: information will be computed, rather than simply digitized, analyzed rather than simply stored. Similarly, I prefer the term /analysis/ over others such as /reading/, which I feel unnecessarily anthropomorphizes the task.
Franco Moretti, one of the field's most-cited theorists, famously calls his practice "distant reading," to contrast it with close reading, one of the most typical critical functions for literary scholars [cite:@moretti_distant_2013]. In his monograph of the same name, he outlines his logic:

#+begin_quote
"[T]he trouble with close reading (in all of its incarnations, from the new criticism to deconstruction) is that it necessarily depends on an extremely small canon. ... [W]e know how to read texts, now let's learn how /not/ to read them. Distant reading: where distance, ... /is a condition of knowledge/: it allows you to focus on units that are much smaller or much larger than the text: devices, themes, tropes---or genres and systems. And if, between the very small and the very large, the text itself disappears, well, it is one of those cases when one can justifiably say, Less is more." [cite:@moretti_distant_2013 49]
#+end_quote

Moretti is not wrong that the scale or scope of an analysis determines its results, but the close/distant pair, is less mutually exclusive than it may seem from this polemic. In practice, close and distant reading complement each other perfectly: a large scale analysis of many hundreds or thousands of novels, like some of those I present in this dissertation, can identify works of literature outside the canon that have been ignored by critics, yet which stand in useful dialogue to canonical works and existing literary-theoretic discussions.

Ted Underwood also uses this term [cite:@underwood2019distant]; Matthew Jockers prefers "macroanalysis" [cite:@jockers_macroanalysis:_2013]; Andrew Piper, in /Enumerations/ studies quantitative aspects of literature through computational literary studies [cite:@piper2018enumerations].

* Corpus

The problem of corpus creation was one of the most difficult problems I had to solve as a preliminary to the analyses of the following chapters. I wanted to limit my analysis to British literature of the 19th and 20th centuries, for several reasons. The first of which is the disciplinary divide which divides British literature into medieval, early modern, Victorian, and modernist camps: by limiting the scope of my analysis to these years, I can more cleanly engage with the scholarship which discusses this period.
The Modern Language Association, for instance, divides its forums into categories such as "Late-18th-Century English," "English Romantic," "Victorian and Early-20th-Century English," and "20th- and 21st-Century English and Anglophone" [cite:@mla_forums].
These divisions aren't arbitrary, but use different criteria in each: "Late-18th-Century" is a portion of a century; "English Romantic" is another such portion, but designated by its most prominent genre or era; "Victorian and Early-20th-Century" is both the only regnal era /and/ the portion of a century that followed; and "20th- and 21st-Century English and Anglophone" suddenly includes all anglophone literature. I will be working roughly within the Victorian and early twentieth century periods, but with some differences: in order to show the explosion of color and shape in the 1880--1930 period, I often have to rewind to 1800, to provide the necessary context.

Another reason for choosing this period is more practical: spelling is relatively stable in these centuries than in prior periods. This same reason leads me to restrict my scope to British literature, rather than American, not only because this is my primary realm of expertise, but because the spelling and styles of these texts are more stable than in American texts.
Furthermore, United States copyright law limits me to texts published before 1922, so while I will present charts that go up until 1930, the number of texts included beyond those years tends to fall off dramatically after 1922.

A further concern is that the twentieth century's advances in international travel, communications, and publishing begin to blur the lines between English/British and other Anglophone literatures. I suspect this is one of the main reasons for the MLA's inclusion of all anglophone literature in the later twentieth century. Even in the early twentieth century, British literature is not so easy to define. The term as it is typically used includes the literatures of England, Wales, and Scotland, but often only those written in English, excluding Welsh, Scots, Scottish Gaelic, Cornish, and other languages of Great Britain. For practical reasons, I consider works of British literature, written in English.

What is British, geographically, however, is even more difficult to define. Depending on the time period, the designation includes works from the British empire. Prior to Irish independence, for instance, Ireland was considered British. This is further confounded by the fact that many of the major figures of the British avant-garde were in fact American expatriates, living and and working in London. T.S. Eliot was born in Missouri, but moved to England at 25, where he lived for the rest of his life, eventually renouncing his American citizenship. Ezra Pound left America at 23, spending most of his life in England and on the continent, and wouldn't return until facing trial for treason in the United States, and being committed to a mental institution. And Katherine Mansfield, a figure I will return to throughout, was an expatriate from New Zealand. These are not simple disparities to resolve, as we can rely on neither their legal nationality, nor their publishing history, nor even their own statements of national affinity.

So I needed a way to delineate British Literature, but since manually assembling a corpus would not only have been tedious, but impossible on the level of thousands of books, I also needed to compile a corpus programatically. For that, I turned to the Library of Congress classification, where the label "PR," denotes British Literature. There are many texts that are included in this classification that are surprising, and there are surprising omissions, as well. Mansfield's works are usually classified as "PR," Pound's as "PS" (American literature), and Eliot's, though he was legally and spiritually British, having joined the Church of England later in life, both "PR" and "PS," depending. In the end, allowing the librarians to choose the boundaries of what is British freed me from hundreds of micro-decisions, such as whether James Joyce would've preferred to have been called British or Irish.

Years of corpus collecting, cleaning, and arranging led me to compile several large text repositories. The most notable of these was a virtually uncurated collection of about sixty thousand texts from the British Library, mostly from the nineteenth century. With participation from the members of the Literary Modeling and Visualization Lab, and several other volunteers, I started a project called [[https://git-lit.github.io/][Git-Lit]] to convert them from ALTO-XML, the format they were distributed in, clean them of OCR errors, and create version-controlled repositories for them, using the distributed version control system Git [cite:@Reeve2015GitLit].
I also experimented with compiling corpora by combining the English-language portion of the .txtLab Novel450 collection and the Corpus of English Novels, and by scraping sources outside the US, such as Project Gutenberg Australia [cite:@piper2016novel450;@desmet2008corpus]. However, when combining corpora, inconsistencies between texts with different sources often lead to imbalanced results, which was especially undesirable for diachronic studies like the ones to follow.

One of the guiding concerns of this corpus creation process was the difference between canonical and archival texts. The "canon/archive" question is one which has been much discussed in recent years, especially due to the new prevalence of electronic texts. In computational literary analysis, this
appears especially often, with three pamphlets of the Stanford Literary Lab on the subject, and several other studies of curricula, reading lists, and "classics" [cite:@algee-hewitt_between_2015;@algee2016canon;@porter2018popularity;@González2021Measuring;@walsh2021].
The British Library texts were heavily archival, i.e., containing texts which have entirely been forgotten over the years; Project Gutenberg Australia and Canada texts were also heavily archival, containing Australiana and Canadiana which are of less interest to British literary-historical studies. While the arguments for exploring the so-called "great unread" of the archive are admirable, engaging with literary criticism at all would require work with canonical texts [cite:@reid2019distant].
Ultimately, I chose a single corpus, in order to have a consistent set of copyright restrictions, text quality, and other factors, and to balance works from both the canon and the archive.

My primary source of electronic texts then became [[https://www.gutenberg.org/][Project Gutenberg]], a repository of over 60,000 electronic texts, in operation since 1971 [cite:@hart1992]. The texts in Project Gutenberg were originally hand-keyed, i.e., manually entered into a computer, and proofread by a team known as [[https://www.pgdp.net/c/][Distributed Proofreaders]]. This allows the texts, in comparison to those generated via optical character recognition, or OCR, to be of relatively high quality, without textual errors that could confound statistical results.

Project Gutenberg contains a mix of canonical texts, like James Joyce's /Ulysses/, with lesser-known texts, such as Richard Jefferies's /Round about a Great Estate/, a work that will show up again and again in the chapters to come. While this has the effect of introducing texts that will be unknown and irrelevant to the average literary scholar, it also situates canonical texts within a larger tradition, and more importantly, within a generic milieu that teaches us more about the canonic works. My analysis of these "archival" works is not an attempt to rewrite the canon, by introducing new, ignored works, but to expand our understanding of the canonical works. Even if we have never seen or heard of Jefferies's book, to know it as a work of rural nature writing with a keen eye for detail will help to illuminate why it is so often found clustered with other detailed novels such as /Ulysses/.

One major drawback of Project Gutenberg, however, is that the metadata for its texts are not as complete as with other text repositories. Each text has metadata fields for title and author, a Project Gutenberg "bookshelf", a Library of Congress class, or category, a Library of Congress subject heading, and the date of its publication on Project Gutenberg.
One missing field---one which would be the most useful field for computational literary history---is the date of original publication. To find this, I had to devise a method for augmenting Project Gutenberg metadata with information from other public data repositories.
To accomplish that, I created a database and API called [[http://corpus-db.org/][Corpus-DB]], which aggregates electronic texts from Project Gutenberg and other repositories, and augments their metadata using several external sources [cite:@Reeve2020CorpusDB]. I developed this project over the course of several years, with the help of a few students and other volunteers. To augment the metadata, I [[https://github.com/JonathanReeve/gitenberg-experiments/blob/master/pg-add-dbpedia.ipynb][used the title and author of the texts to create SPARQL queries]] to query the graph knowledge databases such as DBPedia and Wikidata [cite:@auer2007dbpedia;@lehmann2015dbpedia;@vrandevcic2012wikidata;@vrandevcic2014wikidata]. Both dictionary-based knowledge graphs, these databases maintain statements in the form of triples, e.g., ~<Ulysses> <first published> <1922>~. A SPARQL query could then ask the database engine to solve for date of first publication, given the title and author of a text.

The problem with this approach, though, is that it can only find these data for books which already have a Wikipedia article or entry within a larger article. That severely limits the number of books, to 1,647, or, the total number of books from Project Gutenberg, from the Library of Congress classification "PR," originally written in English, which have Wikipedia articles that also name their dates of original publication, and which were first published between 1800 and 1922. This corpus I'll be calling $C_{PG2}$. A subset of that corpus which starts later, for the purpose of zooming in on the 1880--1930 era, I'll call $C_{PG}$.

I also gleaned some additional book data from APIs from [[https://github.com/JonathanReeve/gitenberg-experiments/blob/master/pg-add-amazon.ipynb][Amazon]], [[https://github.com/JonathanReeve/gitenberg-experiments/blob/master/pg-add-goodreads.ipynb][Goodreads]], and Open Library. In those cases where metadata diverged, for example when there were different publication dates, I developed an algorithm to guess the best one (usually the earliest). From this process, I was able to find several thousand texts and associate them with their publication dates. From there, I also did some basic deduplication, using document embeddings to guess duplicate texts.

* Technologies

I developed four independent software programs for this project, as well as a large number of scripts for analytic tasks, using the Python and Haskell programming languages, among others.
The four main programs, which are included in this repository as submodules, are as follows:
- [[https://github.com/JonathanReeve/color-word-analyzer][color-word-analyzer]]: a CLI program and web app to analyze color in a text, for Chapter 1
- [[https://github.com/JonathanReeve/custom-ngrams-search][custom-ngrams-search]]: a framework for searching Google NGrams data for custom textual patterns, for Chapter 1
- [[https://github.com/JonathanReeve/count-objects][count-objects]]: software for counting objects in literary texts, using word sense disambiguation, for Chapter 2
- [[https://github.com/JonathanReeve/description-detection][description-detection]]: a program for probabilistically detecting literary description, for Chapter 3

Each of these programs are usable by readers or third parties, and are accompanied with documentation that explain their usage. Each is also accompanied with the inclusion of reproducible build programs in the Nix language which ensure that these programs will be executable for years to come [fn::For the use of the Nix package manager for reproducibility in science, see [cite/t:@devresse2015nix].].

The text of this dissertation itself, too, is the product of a non-trivial amount of programming.
What you are reading is a richly-formatted, interactive document, presented in HTML, and using JavaScript libraries for interactivity. I made the unconventional decision to produce this dissertation in HTML, rather than produce a Microsoft Word document or a PDF file, to take advantage of recent advances in web publishing.
There is a growing trend of so-called "digital dissertations" which use interactive features, and produce documents that are less linear than usual.[fn::See [cite:@fox2004electronic].]
# TODO: examples of digital dissertations
But the "digital" designation is becoming increasingly meaningless, since PDFs and Word documents, as much as they mimic paper, are still digital. Still, as much as this is a digital dissertation, I hope that it is not a novelty, or merely an experiment in form, but an literary-critical argument which happens to take advantage of some of the more recent textual technologies.

Since Word and PDF were created as proprietary formats, developed by Microsoft and Adobe, they were made to sell software, rather than contribute to the community. Furthermore, they are made to mimic the paper office, using a virtual 8.5 by 11 inch "page." Since this dissertation will not be printed, this constraint is unnecessary. HTML, on the other hand, is much more featureful markup language, allowing for interactive charts, hyperlinks, variable page width, and much, much more. Since it it always-already published on the Internet, it is much more easily archivable, readable with a wider variety of reading software (web browsers), and provides a more seamless experience for those using screen readers or other accessibility software.

One of the most important features of this HTML format is the capability to embed interactive charts. An interactive chart, like some of the scatter plots I present in Chapter 1, allow the reader the ability to see which texts account for the overall diachronic trends, by hovering the mouse pointer over a point, or selecting a range of points by dragging the mouse over a region.

This text is originally written in a feature-rich markup language called [[https://orgmode.org/][Org]], which compiles to HTML.
The software stack that transforms [[https://github.com/JonathanReeve/dissertation/][the source code]] into its final version contains a number of innovations:
 - A [[https://github.com/JonathanReeve/dissertation/blob/master/Shakefile.hs][Shakefile]] written in Haskell, for the [[https://shakebuild.com/][Shake build system]], which interfaces with Pandoc to convert plain text files to HTML, which I originally wrote in [[https://orgmode.org/][the org-mode text format]].
 - [[https://github.com/JonathanReeve/dissertation/blob/master/Template.hs][A template]] written in [[https://chrisdone.com/posts/lucid/][Lucid]] and [[http://fvisser.nl/clay/][Clay]], Haskell domain-specific languages for HTML and CSS, which integrates [[https://edwardtufte.github.io/tufte-css/][Tufte-CSS]], [[https://mermaid-js.github.io/mermaid/#/][Mermaid]] diagram capability, and more.
 - Custom Pandoc filters, written in Haskell: [[https://github.com/JonathanReeve/dissertation/blob/master/templates/hexFilter.hs][one for displaying color hex values]], used in Chapter 1, and [[https://github.com/JonathanReeve/dissertation/blob/master/templates/synsetFilter.hs][one for displaying WordNet synsets]], used in Chapter 2.
 - Semantic tagging, using the [[https://schema.org][Schema.org]] [[https://schema.org/Thesis][Thesis ontology]].

This technological stack I've then abstracted into the template project [[https://github.com/JonathanReeve/template-dissertation][template-dissertation]], a standards-focused, HTML-first dissertation build system, so that it can be used by others.

* Works Cited
